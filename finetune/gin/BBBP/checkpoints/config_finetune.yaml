batch_size: 32
dataset:
  num_workers: 4
  splitting: random
  test_size: 0.1
  valid_size: 0.1
epochs: 100
eval_every_n_epochs: 1
fine_tune_from: pretrained_gin
fp16_precision: false
gpu: cuda:0
init_base_lr: 0.0001
init_lr: 0.0005
log_every_n_steps: 50
model:
  drop_ratio: 0.3
  emb_dim: 300
  feat_dim: 512
  num_layer: 5
  pool: mean
model_type: gin
task_name: BBBP
weight_decay: 1e-6
